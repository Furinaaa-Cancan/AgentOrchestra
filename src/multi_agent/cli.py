"""CLI entry point â€” ma go / ma done / ma status / ma cancel / ma watch."""

from __future__ import annotations

import hashlib
import json
import sys
import time

import click

from multi_agent.workspace import (
    acquire_lock,
    clear_runtime,
    ensure_workspace,
    read_lock,
    read_outbox,
    release_lock,
    save_task_yaml,
)


def _thread_id(task_id: str) -> str:
    return task_id


def _make_config(task_id: str) -> dict:
    return {"configurable": {"thread_id": _thread_id(task_id)}}


def _generate_task_id(requirement: str) -> str:
    content = f"{requirement}-{time.time()}"
    h = hashlib.sha256(content.encode()).hexdigest()[:8]
    return f"task-{h}"


@click.group()
def main():
    """ma â€” Multi-Agent åä½œ CLI. ä¸€æ¡å‘½ä»¤åè°ƒå¤šä¸ª IDE AI."""
    pass


@main.command()
@click.argument("requirement")
@click.option("--skill", default="code-implement", help="Skill ID to use")
@click.option("--task-id", default=None, help="Override task ID")
@click.option("--builder", default="", help="IDE for builder role (e.g. windsurf, cursor, kiro)")
@click.option("--reviewer", default="", help="IDE for reviewer role (e.g. cursor, codex, kiro)")
@click.option("--retry-budget", default=2, type=int, help="Max retries")
@click.option("--timeout", default=1800, type=int, help="Timeout in seconds")
@click.option("--no-watch", is_flag=True, default=False, help="Don't auto-watch (exit after start)")
@click.option("--decompose", is_flag=True, default=False, help="Decompose complex requirement into sub-tasks first")
def go(requirement: str, skill: str, task_id: str | None, builder: str, reviewer: str, retry_budget: int, timeout: int, no_watch: bool, decompose: bool):
    """Start a new task and watch for IDE output.

    Starts the task, then auto-watches outbox/ for agent output.
    When the IDE AI saves its result, the orchestrator auto-advances.

    Usage:
      1. Run: ma go "your requirement"
      2. Open .multi-agent/TASK.md in your IDE
      3. Watch the terminal â€” it handles the rest

    Examples:
      ma go "å®žçŽ° POST /users endpoint"
      ma go "Add auth middleware" --builder windsurf --reviewer cursor
      ma go "Fix login bug" --no-watch
      ma go "å®žçŽ°å®Œæ•´ç”¨æˆ·è®¤è¯æ¨¡å—" --decompose
    """
    from multi_agent.graph import compile_graph

    ensure_workspace()

    # Enforce single active task â€” prevent data conflicts
    app = compile_graph()
    locked = read_lock()
    if locked:
        click.echo(f"âŒ ä»»åŠ¡ '{locked}' æ­£åœ¨è¿›è¡Œä¸­ã€‚", err=True)
        click.echo(f"   å…ˆå®Œæˆæˆ–å–æ¶ˆå½“å‰ä»»åŠ¡:", err=True)
        click.echo(f"   â€¢ ma cancel   â€” å–æ¶ˆå½“å‰ä»»åŠ¡", err=True)
        click.echo(f"   â€¢ ma done     â€” æ‰‹åŠ¨æäº¤ç»“æžœ", err=True)
        click.echo(f"   â€¢ ma status   â€” æŸ¥çœ‹ä»»åŠ¡çŠ¶æ€", err=True)
        sys.exit(1)

    task_id = task_id or _generate_task_id(requirement)

    # Clear ALL shared runtime files to prevent stale data leaking
    clear_runtime()

    # Acquire lock â€” marks this task as the sole active task
    acquire_lock(task_id)

    if decompose:
        _run_decomposed(app, task_id, requirement, skill, builder, reviewer,
                        retry_budget, timeout, no_watch)
        return

    _run_single_task(app, task_id, requirement, skill, builder, reviewer,
                     retry_budget, timeout, no_watch)


def _run_single_task(app, task_id, requirement, skill, builder, reviewer,
                     retry_budget, timeout, no_watch):
    """Run a single monolithic build-review cycle (original behavior)."""
    initial_state = {
        "task_id": task_id,
        "requirement": requirement,
        "skill_id": skill,
        "done_criteria": [requirement],
        "timeout_sec": timeout,
        "retry_budget": retry_budget,
        "retry_count": 0,
        "input_payload": {"requirement": requirement},
        "builder_explicit": builder,
        "reviewer_explicit": reviewer,
        "conversation": [],
    }

    click.echo(f"ðŸš€ Task: {task_id}")
    click.echo(f"   {requirement}")
    click.echo()

    config = _make_config(task_id)

    # Run until first interrupt (plan â†’ build interrupt)
    from langgraph.errors import GraphInterrupt
    try:
        app.invoke(initial_state, config)
    except GraphInterrupt:
        pass
    except FileNotFoundError as e:
        release_lock()
        click.echo(f"âŒ {e}", err=True)
        click.echo(f"   ç¡®è®¤ä½ åœ¨ AgentOrchestra é¡¹ç›®æ ¹ç›®å½•è¿è¡Œ, ä¸” skills/ å’Œ agents/ å­˜åœ¨ã€‚", err=True)
        click.echo(f"   æˆ–è®¾ç½® MA_ROOT çŽ¯å¢ƒå˜é‡æŒ‡å‘é¡¹ç›®æ ¹ç›®å½•ã€‚", err=True)
        save_task_yaml(task_id, {"task_id": task_id, "status": "failed", "error": str(e)})
        sys.exit(1)
    except ValueError as e:
        release_lock()
        click.echo(f"âŒ {e}", err=True)
        click.echo(f"   æ£€æŸ¥ agents/agents.yaml é…ç½®æ˜¯å¦æ­£ç¡®ã€‚", err=True)
        save_task_yaml(task_id, {"task_id": task_id, "status": "failed", "error": str(e)})
        sys.exit(1)
    except Exception as e:
        release_lock()
        click.echo(f"âŒ Task failed to start: {e}", err=True)
        save_task_yaml(task_id, {"task_id": task_id, "status": "failed", "error": str(e)})
        sys.exit(1)

    save_task_yaml(task_id, {"task_id": task_id, "skill": skill, "status": "active"})

    # Show what to do
    _show_waiting(app, config)

    if no_watch:
        click.echo("\nðŸ“Œ Run `ma done` after the IDE finishes, or `ma watch` to auto-detect.")
        return

    # Auto-watch mode (default) â€” poll outbox and auto-submit
    _run_watch_loop(app, config, task_id)


def _run_decomposed(app, parent_task_id, requirement, skill, builder, reviewer,
                    retry_budget, timeout, no_watch):
    """Decompose â†’ sequential sub-task build-review cycles â†’ aggregate."""
    from multi_agent.decompose import write_decompose_prompt, read_decompose_result, topo_sort
    from multi_agent.meta_graph import build_sub_task_state, aggregate_results
    from langgraph.errors import GraphInterrupt

    click.echo(f"ðŸ§© Task Decomposition: {parent_task_id}")
    click.echo(f"   {requirement}")
    click.echo()

    save_task_yaml(parent_task_id, {
        "task_id": parent_task_id, "status": "active", "mode": "decompose",
    })

    # Phase 1: Write decompose prompt â†’ wait for agent to decompose
    write_decompose_prompt(requirement)
    click.echo(f"ðŸ“‹ åˆ†è§£ä»»åŠ¡ä¸­â€¦ åœ¨ IDE é‡Œå¯¹ AI è¯´:")
    click.echo(f'   "å¸®æˆ‘å®Œæˆ @.multi-agent/TASK.md é‡Œçš„ä»»åŠ¡"')

    # Check if builder has CLI driver â†’ auto-spawn for decomposition
    from multi_agent.driver import get_agent_driver, spawn_cli_agent, can_use_cli
    from multi_agent.router import load_agents
    agents = load_agents()
    decompose_agent = builder if builder else (agents[0].id if agents else "?")
    drv = get_agent_driver(decompose_agent)
    if drv["driver"] == "cli" and drv["command"] and can_use_cli(drv["command"]):
        click.echo(f"ðŸ¤– è‡ªåŠ¨è°ƒç”¨ {decompose_agent} CLI è¿›è¡Œä»»åŠ¡åˆ†è§£â€¦")
        spawn_cli_agent(decompose_agent, "decompose", drv["command"], timeout_sec=timeout)

    click.echo(f"ðŸ‘ï¸  ç­‰å¾…ä»»åŠ¡åˆ†è§£ç»“æžœâ€¦ (Ctrl-C åœæ­¢)")

    # Poll for decompose.json (with timeout)
    decompose_result = None
    deadline = time.time() + timeout
    try:
        while decompose_result is None:
            decompose_result = read_decompose_result()
            if decompose_result:
                break
            if time.time() > deadline:
                click.echo(f"âŒ ä»»åŠ¡åˆ†è§£è¶…æ—¶ ({timeout}s)ã€‚", err=True)
                release_lock()
                clear_runtime()
                sys.exit(1)
            time.sleep(2)
    except KeyboardInterrupt:
        click.echo(f"\nâ¹ï¸  Decomposition stopped.")
        release_lock()
        clear_runtime()
        return

    # Phase 2: Sort sub-tasks by dependencies
    try:
        sorted_tasks = topo_sort(decompose_result.sub_tasks)
    except ValueError as e:
        click.echo(f"âŒ åˆ†è§£ç»“æžœæ— æ•ˆ: {e}", err=True)
        release_lock()
        clear_runtime()
        sys.exit(1)

    if not sorted_tasks:
        click.echo(f"âš ï¸  åˆ†è§£ç»“æžœä¸ºç©ºï¼Œé™çº§ä¸ºå•ä»»åŠ¡æ¨¡å¼")
        _run_single_task(app, parent_task_id, requirement, skill, builder, reviewer,
                         retry_budget, timeout, no_watch)
        return

    click.echo(f"\nâœ… åˆ†è§£å®Œæˆ: {len(sorted_tasks)} ä¸ªå­ä»»åŠ¡")
    if decompose_result.reasoning:
        click.echo(f"   ç†ç”±: {decompose_result.reasoning}")
    for i, st in enumerate(sorted_tasks, 1):
        deps_str = f" (ä¾èµ–: {', '.join(st.deps)})" if st.deps else ""
        click.echo(f"   {i}. {st.id}: {st.description}{deps_str}")
    click.echo()

    # Phase 3: Execute each sub-task sequentially
    prior_results: list[dict] = []
    failed_ids: set[str] = set()  # track failed sub-task IDs for dep skipping

    for i, st in enumerate(sorted_tasks, 1):
        # Skip sub-tasks whose dependencies failed
        skipped_deps = [d for d in st.deps if d in failed_ids]
        if skipped_deps:
            click.echo(f"\nâ­ï¸  è·³è¿‡ {st.id}: ä¾èµ– {', '.join(skipped_deps)} å·²å¤±è´¥")
            prior_results.append({
                "sub_id": st.id, "status": "skipped",
                "summary": f"Skipped: dependency {', '.join(skipped_deps)} failed",
                "changed_files": [], "retry_count": 0,
            })
            failed_ids.add(st.id)
            continue

        click.echo(f"\n{'='*60}")
        click.echo(f"  ðŸ“¦ Sub-task {i}/{len(sorted_tasks)}: {st.id}")
        click.echo(f"  {st.description}")
        click.echo(f"{'='*60}")

        # Clear runtime for this sub-task
        clear_runtime()

        sub_state = build_sub_task_state(
            sub_task=st,
            parent_task_id=parent_task_id,
            builder=builder,
            reviewer=reviewer,
            timeout=timeout,
            retry_budget=retry_budget,
            prior_results=prior_results,
        )
        sub_task_id = sub_state["task_id"]
        sub_config = _make_config(sub_task_id)

        # Run sub-task graph
        try:
            app.invoke(sub_state, sub_config)
        except GraphInterrupt:
            pass
        except Exception as e:
            click.echo(f"âŒ Sub-task {st.id} failed to start: {e}", err=True)
            prior_results.append({
                "sub_id": st.id, "status": "failed",
                "summary": str(e), "changed_files": [], "retry_count": 0,
            })
            failed_ids.add(st.id)
            continue

        # Show waiting + watch loop for this sub-task
        _show_waiting(app, sub_config)

        if no_watch:
            click.echo(f"ðŸ“Œ Sub-task {st.id}: ç­‰å¾…æ‰‹åŠ¨ ma done")
            click.echo(f"âš ï¸  --no-watch æ¨¡å¼ä¸‹ --decompose åªæ‰§è¡Œç¬¬ä¸€æ­¥åˆ†è§£ã€‚")
            click.echo(f"   åŽç»­è¯·é€ä¸ªæ‰‹åŠ¨æ‰§è¡Œå„å­ä»»åŠ¡ã€‚")
            save_task_yaml(parent_task_id, {
                "task_id": parent_task_id, "status": "decomposed",
                "sub_tasks": [s.model_dump() for s in sorted_tasks],
            })
            return

        # manage_lock=False: don't release parent lock between sub-tasks
        _run_watch_loop(app, sub_config, sub_task_id, manage_lock=False)

        # Collect result
        snapshot = app.get_state(sub_config)
        vals = snapshot.values if snapshot else {}
        builder_out = vals.get("builder_output", {})
        if not isinstance(builder_out, dict):
            builder_out = {}

        sub_status = vals.get("final_status", "unknown")
        prior_results.append({
            "sub_id": st.id,
            "status": sub_status,
            "summary": builder_out.get("summary", ""),
            "changed_files": builder_out.get("changed_files", []),
            "retry_count": vals.get("retry_count", 0),
        })
        if sub_status not in ("approved", "completed"):
            failed_ids.add(st.id)

    # Phase 4: Aggregate
    click.echo(f"\n{'='*60}")
    click.echo(f"  ðŸ“Š æ±‡æ€»ç»“æžœ")
    click.echo(f"{'='*60}")

    agg = aggregate_results(parent_task_id, prior_results)

    click.echo(f"  æ€»å­ä»»åŠ¡: {agg['total_sub_tasks']}")
    click.echo(f"  å®Œæˆ: {agg['completed']}")
    click.echo(f"  æ€»é‡è¯•: {agg['total_retries']}")
    if agg["failed"]:
        click.echo(f"  âŒ å¤±è´¥: {', '.join(agg['failed'])}")
    else:
        click.echo(f"  âœ… å…¨éƒ¨é€šè¿‡")
    click.echo(f"  ä¿®æ”¹æ–‡ä»¶: {', '.join(agg['all_changed_files']) or 'æ— '}")
    click.echo()

    save_task_yaml(parent_task_id, {
        "task_id": parent_task_id, "status": agg["final_status"],
        "sub_results": prior_results,
    })
    release_lock()
    clear_runtime()


@main.command()
@click.option("--task-id", default=None, help="Task ID (auto-detect if only one active)")
@click.option("--file", "file_path", default=None, type=click.Path(exists=True), help="Read output from file")
def done(task_id: str | None, file_path: str | None):
    """æ‰‹åŠ¨æäº¤ IDE è¾“å‡ºå¹¶æŽ¨è¿›ä»»åŠ¡.

    è‡ªåŠ¨ä»Ž .multi-agent/outbox/ è¯»å–å½“å‰è§’è‰²çš„ JSON è¾“å‡º,
    ä¹Ÿå¯ç”¨ --file æŒ‡å®šæ–‡ä»¶, æˆ–ä»Ž stdin ç²˜è´´.
    """
    from multi_agent.graph import compile_graph

    app = compile_graph()

    if not task_id:
        task_id = _detect_active_task(app)
        if not task_id:
            click.echo("âŒ No active task found. Specify --task-id.", err=True)
            sys.exit(1)

    config = _make_config(task_id)
    snapshot = app.get_state(config)

    if not snapshot or not snapshot.next:
        click.echo("âŒ No pending interrupt for this task.", err=True)
        sys.exit(1)

    # Determine current role and agent from interrupt metadata
    role = "builder"
    agent_id = "?"
    if snapshot.tasks and snapshot.tasks[0].interrupts:
        info = snapshot.tasks[0].interrupts[0].value
        role = info.get("role", "builder")
        agent_id = info.get("agent", "?")

    # Read output: --file > role-based outbox > stdin
    output_data = None

    if file_path:
        try:
            with open(file_path, "r", encoding="utf-8") as f:
                output_data = json.load(f)
        except json.JSONDecodeError as e:
            click.echo(f"âŒ Invalid JSON in {file_path}: {e}", err=True)
            sys.exit(1)
    else:
        # Role-based outbox: outbox/builder.json or outbox/reviewer.json
        output_data = read_outbox(role)

    if output_data is None:
        click.echo(f"ðŸ“ No output in outbox/{role}.json. Paste JSON (Ctrl-D to end):")
        raw = sys.stdin.read().strip()
        if raw:
            try:
                output_data = json.loads(raw)
            except json.JSONDecodeError as e:
                click.echo(f"âŒ Invalid JSON: {e}", err=True)
                sys.exit(1)

    if output_data is None:
        click.echo(f"âŒ No output found. Save to .multi-agent/outbox/{role}.json or use --file.", err=True)
        sys.exit(1)

    click.echo(f"ðŸ“¤ Submitting {role} output for task {task_id} (IDE: {agent_id})")

    from langgraph.types import Command
    from langgraph.errors import GraphInterrupt
    try:
        result = app.invoke(Command(resume=output_data), config)
    except GraphInterrupt:
        pass  # Normal â€” graph paused at next interrupt()
    except Exception as e:
        release_lock()
        clear_runtime()
        click.echo(f"âŒ Graph error during resume: {e}", err=True)
        save_task_yaml(task_id, {"task_id": task_id, "status": "failed", "error": str(e)})
        sys.exit(1)

    # Mark task completed if graph finished
    snapshot = app.get_state(config)
    if snapshot and not snapshot.next:
        vals = snapshot.values or {}
        final = vals.get("final_status", "")
        if final:
            save_task_yaml(task_id, {"task_id": task_id, "status": final})
        release_lock()
        clear_runtime()

    _show_waiting(app, config)


@main.command()
@click.option("--task-id", default=None, help="Task ID")
def status(task_id: str | None):
    """Show current task status."""
    from multi_agent.graph import compile_graph

    app = compile_graph()

    if not task_id:
        task_id = _detect_active_task(app)
        if not task_id:
            click.echo("No active tasks.")
            return

    config = _make_config(task_id)
    snapshot = app.get_state(config)

    if not snapshot:
        click.echo(f"No state found for task {task_id}")
        return

    vals = snapshot.values
    current_role = vals.get("current_role", "?")
    locked = read_lock()

    click.echo(f"ðŸ“Š Task: {task_id}")
    click.echo(f"   Step:     {current_role}")
    click.echo(f"   Builder:  {vals.get('builder_id', '?')}")
    click.echo(f"   Reviewer: {vals.get('reviewer_id', '?')}")
    click.echo(f"   Retry:    {vals.get('retry_count', 0)}/{vals.get('retry_budget', 2)}")
    click.echo(f"   Lock:     {'ðŸ”’ ' + locked if locked else 'ðŸ”“ none'}")

    if vals.get("error"):
        click.echo(f"   âŒ Error: {vals['error']}")
    if vals.get("final_status"):
        click.echo(f"   ðŸ Final: {vals['final_status']}")

    if snapshot.next:
        agent = vals.get("builder_id" if current_role == "builder" else "reviewer_id", "?")
        from multi_agent.driver import get_agent_driver
        drv = get_agent_driver(agent)
        mode = "ðŸ¤– auto" if drv["driver"] == "cli" else "ðŸ“‹ manual"
        click.echo(f"   â¸ï¸  Waiting: {current_role} ({agent}) [{mode}]")
        if drv["driver"] != "cli":
            click.echo(f'   ðŸ“‹ åœ¨ {agent} IDE é‡Œè¯´: "å¸®æˆ‘å®Œæˆ @.multi-agent/TASK.md é‡Œçš„ä»»åŠ¡"')
    else:
        click.echo("   âœ… Graph complete")


@main.command()
@click.option("--task-id", default=None)
@click.option("--reason", default="user cancelled")
def cancel(task_id: str | None, reason: str):
    """Cancel the current task."""
    from multi_agent.graph import compile_graph

    app = compile_graph()

    if not task_id:
        task_id = _detect_active_task(app)
        if not task_id:
            # Fallback: check for orphaned lock (e.g. after kill -9)
            task_id = read_lock()
            if not task_id:
                click.echo("No active task to cancel.")
                return
            click.echo(f"âš ï¸  å‘çŽ°å­¤ç«‹é” (task: {task_id}), æ­£åœ¨æ¸…ç†â€¦")

    # Mark task YAML as cancelled so auto-detect skips it
    save_task_yaml(task_id, {"task_id": task_id, "status": "cancelled", "reason": reason})

    # Release lock + clean shared files
    release_lock()
    clear_runtime()

    click.echo(f"ðŸ›‘ Task {task_id} cancelled: {reason}")


@main.command()
@click.option("--task-id", default=None)
@click.option("--interval", default=2.0, type=float, help="Poll interval in seconds")
def watch(task_id: str | None, interval: float):
    """è‡ªåŠ¨æ£€æµ‹ IDE è¾“å‡ºå¹¶æŽ¨è¿›ä»»åŠ¡.

    æ¢å¤ä¹‹å‰ä¸­æ–­çš„è‡ªåŠ¨æ£€æµ‹.
    é€‚ç”¨äºŽ `ma go --no-watch` å¯åŠ¨çš„ä»»åŠ¡.
    """
    from multi_agent.graph import compile_graph

    app = compile_graph()

    if not task_id:
        task_id = _detect_active_task(app)
        if not task_id:
            click.echo("âŒ No active task to watch.", err=True)
            sys.exit(1)

    # Validate lock consistency â€” prevent watching wrong task
    locked = read_lock()
    if locked and locked != task_id:
        click.echo(f"âŒ é”æ–‡ä»¶æŒ‡å‘ '{locked}', ä½†ä½ è¦ watch '{task_id}'ã€‚", err=True)
        click.echo(f"   åŒæ—¶åªèƒ½æœ‰ä¸€ä¸ªæ´»è·ƒä»»åŠ¡ã€‚", err=True)
        sys.exit(1)
    if not locked:
        acquire_lock(task_id)

    config = _make_config(task_id)
    snapshot = app.get_state(config)
    if not snapshot or not snapshot.next:
        vals = snapshot.values if snapshot else {}
        final = vals.get("final_status", "done")
        release_lock()
        clear_runtime()
        click.echo(f"âœ… Task {task_id} already finished â€” {final}")
        return
    _show_waiting(app, config)
    _run_watch_loop(app, config, task_id, interval=interval)


def _show_waiting(app, config):
    """Show current waiting state â€” auto-spawn CLI agents or show manual instructions."""
    snapshot = app.get_state(config)
    if not snapshot or not snapshot.next:
        vals = snapshot.values if snapshot else {}
        final = vals.get("final_status", "")
        error = vals.get("error", "")
        if final in ("approved", ""):
            click.echo(f"âœ… Task finished. Status: {final or 'done'}")
        else:
            click.echo(f"âŒ Task finished. Status: {final}{' â€” ' + error if error else ''}")
        return

    role = "builder"
    agent = "?"
    if snapshot.tasks and snapshot.tasks[0].interrupts:
        info = snapshot.tasks[0].interrupts[0].value
        role = info.get("role", "builder")
        agent = info.get("agent", "?")

    step_label = "Build" if role == "builder" else "Review"

    # Check if agent has CLI driver â†’ auto-spawn (with graceful degradation)
    from multi_agent.driver import get_agent_driver, spawn_cli_agent, can_use_cli
    drv = get_agent_driver(agent)
    if drv["driver"] == "cli" and drv["command"]:
        if can_use_cli(drv["command"]):
            vals = snapshot.values or {}
            timeout = vals.get("timeout_sec", 600)
            click.echo(f"ðŸ¤– [{step_label}] è‡ªåŠ¨è°ƒç”¨ {agent} CLIâ€¦")
            spawn_cli_agent(agent, role, drv["command"], timeout_sec=timeout)
        else:
            binary = drv["command"].split()[0]
            click.echo(f"âš ï¸  {agent} é…ç½®ä¸º CLI æ¨¡å¼ä½† `{binary}` æœªå®‰è£…ï¼Œé™çº§ä¸ºæ‰‹åŠ¨æ¨¡å¼")
            click.echo(f"ðŸ“‹ [{step_label}] åœ¨ {agent} IDE é‡Œå¯¹ AI è¯´:")
            click.echo(f'   "å¸®æˆ‘å®Œæˆ @.multi-agent/TASK.md é‡Œçš„ä»»åŠ¡"')
    else:
        click.echo(f"ðŸ“‹ [{step_label}] åœ¨ {agent} IDE é‡Œå¯¹ AI è¯´:")
        click.echo(f'   "å¸®æˆ‘å®Œæˆ @.multi-agent/TASK.md é‡Œçš„ä»»åŠ¡"')
    click.echo()


def _run_watch_loop(app, config, task_id: str, interval: float = 2.0, manage_lock: bool = True):
    """Shared watch loop â€” polls outbox/ and auto-submits output."""
    from multi_agent.watcher import OutboxPoller
    from langgraph.types import Command
    from langgraph.errors import GraphInterrupt

    poller = OutboxPoller(poll_interval=interval)
    start_time = time.time()

    click.echo(f"ðŸ‘ï¸  ç­‰å¾… IDE å®Œæˆä»»åŠ¡â€¦ (Ctrl-C åœæ­¢)")
    click.echo()

    try:
        while True:
            elapsed = int(time.time() - start_time)
            mins, secs = divmod(elapsed, 60)

            snapshot = app.get_state(config)
            if not snapshot or not snapshot.next:
                vals = snapshot.values if snapshot else {}
                final = vals.get("final_status", "")
                if final:
                    save_task_yaml(task_id, {"task_id": task_id, "status": final})
                if manage_lock:
                    release_lock()
                    clear_runtime()
                if final in ("approved", ""):
                    summary = vals.get("builder_output", {}).get("summary", "") if isinstance(vals.get("builder_output"), dict) else ""
                    retries = vals.get("retry_count", 0)
                    click.echo(f"[{mins:02d}:{secs:02d}] âœ… Task finished â€” {final or 'done'}")
                    if summary:
                        click.echo(f"             {summary}")
                    if retries:
                        click.echo(f"             (ç»è¿‡ {retries} æ¬¡é‡è¯•)")
                else:
                    error = vals.get("error", "")
                    click.echo(f"[{mins:02d}:{secs:02d}] âŒ Task finished â€” {final}{' â€” ' + error if error else ''}")
                return

            # Determine which role we're waiting for
            role = "builder"
            agent = "?"
            if snapshot.tasks and snapshot.tasks[0].interrupts:
                info = snapshot.tasks[0].interrupts[0].value
                role = info.get("role", "builder")
                agent = info.get("agent", "?")

            for detected_role, data in poller.check_once():
                if detected_role == role:
                    step_label = "Build" if role == "builder" else "Review"
                    click.echo(f"[{mins:02d}:{secs:02d}] ðŸ“¥ {step_label} å®Œæˆ ({agent})")
                    try:
                        app.invoke(Command(resume=data), config)
                    except GraphInterrupt:
                        pass
                    except Exception as e:
                        if manage_lock:
                            release_lock()
                            clear_runtime()
                        click.echo(f"[{mins:02d}:{secs:02d}] âŒ Error: {e}", err=True)
                        save_task_yaml(task_id, {"task_id": task_id, "status": "failed", "error": str(e)})
                        return

                    # Show next waiting state or completion
                    next_snap = app.get_state(config)
                    if next_snap and next_snap.next and next_snap.tasks and next_snap.tasks[0].interrupts:
                        next_info = next_snap.tasks[0].interrupts[0].value
                        next_role = next_info.get("role", "?")
                        next_agent = next_info.get("agent", "?")
                        next_label = "Build" if next_role == "builder" else "Review"
                        # Show retry feedback if this is a retry
                        next_vals = next_snap.values or {}
                        retry_n = next_vals.get("retry_count", 0)
                        if retry_n > 0 and next_role == "builder":
                            reviewer_out = next_vals.get("reviewer_output", {})
                            feedback = reviewer_out.get("feedback", "")
                            budget = next_vals.get("retry_budget", 2)
                            click.echo(f"[{mins:02d}:{secs:02d}] ðŸ”„ Reviewer è¦æ±‚ä¿®æ”¹ ({retry_n}/{budget}):")
                            if feedback:
                                click.echo(f"             {feedback}")
                        # Auto-spawn CLI agent or show manual instructions
                        from multi_agent.driver import get_agent_driver, spawn_cli_agent, can_use_cli
                        drv = get_agent_driver(next_agent)
                        if drv["driver"] == "cli" and drv["command"] and can_use_cli(drv["command"]):
                            t_sec = next_vals.get("timeout_sec", 600)
                            click.echo(f"[{mins:02d}:{secs:02d}] ðŸ¤– è‡ªåŠ¨è°ƒç”¨ {next_agent} CLIâ€¦")
                            spawn_cli_agent(next_agent, next_role, drv["command"], timeout_sec=t_sec)
                        else:
                            if drv["driver"] == "cli" and drv["command"] and not can_use_cli(drv["command"]):
                                binary = drv["command"].split()[0]
                                click.echo(f"[{mins:02d}:{secs:02d}] âš ï¸  `{binary}` æœªå®‰è£…ï¼Œé™çº§æ‰‹åŠ¨æ¨¡å¼")
                            click.echo(f"[{mins:02d}:{secs:02d}] ðŸ“‹ åœ¨ {next_agent} IDE é‡Œå¯¹ AI è¯´:")
                            click.echo(f'             "å¸®æˆ‘å®Œæˆ @.multi-agent/TASK.md é‡Œçš„ä»»åŠ¡"')
                    break

            time.sleep(interval)
    except KeyboardInterrupt:
        click.echo(f"\nâ¹ï¸  Watch stopped. Task still active â€” resume with: ma watch")


def _detect_active_task(app=None) -> str | None:
    """Detect the active task from task YAML markers in workspace."""
    from multi_agent.config import tasks_dir
    td = tasks_dir()
    if not td.exists():
        return None
    yamls = sorted(td.glob("*.yaml"), key=lambda p: p.stat().st_mtime, reverse=True)
    for yf in yamls:
        try:
            import yaml
            data = yaml.safe_load(yf.read_text(encoding="utf-8")) or {}
            if data.get("status") == "active":
                return yf.stem
        except Exception:
            continue
    return None


if __name__ == "__main__":
    main()
